{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b31ac0c",
   "metadata": {},
   "source": [
    "# Analyzing mother-infant metagenomes to find evidence for plasmid transfer through single-nucleotide variants (SNVs)\n",
    "\n",
    "The purpose of the following workflow is to use read recruitment results obtained from multiple mother-infant gut metagenomes using pBI143 Version 1 sequence to investigate whether unqiue SNVs occur primarily between family members.\n",
    "\n",
    "If you are planning to reproduce this workflow, I would suggest you to download [this jupyter notebook](https://merenlab.org/data/pBI143/files/pBI143_SNVs.ipynb) file on your computer, and follow it from within your local jupyter environment. If you wish to do that, all you need to do is the following, assuming you are in an `anvio-dev` installed environment (the installation instructions for anvio-dev is [here](https://anvio.org/install/)):\n",
    "\n",
    "* Download [this file](https://merenlab.org/data/pBI143/files/pBI143_SNVs.ipynb) on your computer.\n",
    "* In your terminal go to the directory in which you have downloaded the file.\n",
    "* In your terminal type `jupyter notebook`, and select `pBI143_SNVs.ipynb` to start.\n",
    "\n",
    "Alternatively, you can read through the following steps and look at the output files the workflow reports.\n",
    "\n",
    "## Acquiring the data pack\n",
    "\n",
    "The primary input for this analysis is anvi'o project files for four mother-infant datasets from Finalnd, Italy, Sweeden, and the United Stats. The generation of these project files is very straightforward with the program anvi-run-workflow, to which we essentially provided the plasmid sequence and a list of metagenomes of interest. The program anvi-run-workflow simply (1) recruited reads using the plasmid sequence from each metagenome it was given, (2) profiled each read recruitment result using the program anvi-profile, and finally (3) merged all single profile databases using the program anvi-merge. We then moved these final anvi'o project files into four directories (which we will download for reproducibility in a second), where each directory contained a single contigs-db and a single merged profile-db that will enable us to perform the analyses down below. \n",
    "\n",
    "Let's start with downloading the data pack, which is at [doi:10.6084/m9.figshare.22298215](https://doi.org/10.6084/m9.figshare.22298215). In this jupyter notebook environment, I will use an anvi'o function to directly download it to my work directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66f2549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from anvi'o utils library import necessary functions\n",
    "from anvio.utils import download_file, gzip_decompress_file, tar_extract_file\n",
    "\n",
    "# instruct jupyter notebook to download the datapack\n",
    "download_file('https://figshare.com/ndownloader/files/39659905',\n",
    "              output_file_path='MOTHER_INFANT_pBI143_POP_GEN.tar.gz')\n",
    "\n",
    "# if we are here, the download is finished. now we will\n",
    "# first decompress it (and get rid of the original file\n",
    "# while at it).\n",
    "gzip_decompress_file('MOTHER_INFANT_pBI143_POP_GEN.tar.gz',\n",
    "                     keep_original=False)\n",
    "\n",
    "# and finally untar it so we have a clean directory:\n",
    "tar_extract_file('MOTHER_INFANT_pBI143_POP_GEN.tar',\n",
    "                 output_file_path='.',\n",
    "                 keep_original=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e24746",
   "metadata": {},
   "source": [
    "Running the lines above must have created a new directory called `MOTHER_INFANT_pBI143_POP_GEN` in our work directory. Run the `ls` command to confirm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786c0896",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1bee7a",
   "metadata": {},
   "source": [
    "Where the datapack directory should contain four folders as promised:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55b2568",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls MOTHER_INFANT_pBI143_POP_GEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca37a06d",
   "metadata": {},
   "source": [
    "With anvi'o contigs-db and profile-db files in them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86140099",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls MOTHER_INFANT_pBI143_POP_GEN/*/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5021a1",
   "metadata": {},
   "source": [
    "Good. Now we have the raw recruitment results described as anvi'o project files. Now we will change our work directory to the root of the data pack, and start playing with these data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e3e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('MOTHER_INFANT_pBI143_POP_GEN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d67facb",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Unlike the vast majority of data analyses we do with anvi'o using [anvi'o programs](https://anvio.org/help/), here we will perform this analysis by accessing anvi'o libraries directly from within Python scripts we will implement below. Many of these steps use anvi'o functionality that is accessible through two anvi'o programs:\n",
    "\n",
    "* [anvi-gen-variability-profile](https://anvio.org/m/anvi-gen-variability-profile) (which is a program that gives us access to nucleotide, codon, or amino acid variants in metagenomic read recruitment results),\n",
    "* [anvi-gen-variability-network](https://anvio.org/m/anvi-gen-variability-network) (which is a program that turns an anvi'o nucleotide variability report into a Gephi compatible XML network file).\n",
    "\n",
    "But by accessing anvi'o libraries directly, we get to apply filtering rules that are dependent on sample names, such as removing infants from the dataset whose mother does not have a metagenome and vice versa. One could indeed implement those steps after getting the necessary output files from `anvi-gen-variability-profile` using R, EXCEL or by manually selecting samples to be considered for the analysis. But a Pythonic approach helps with reproducibility, and reduces human error.\n",
    "\n",
    "The actual bottom line is the following: these analyses can be done with anvi'o without writing a single line of Python code, too. In addition to reproducibilty, a side purpose of this workflow is to show those who might be interested in exploring anvi'o deeper what else can be done with it. So here we are.\n",
    "\n",
    "Our analysis starts with importing some libraries that will be necessary later (of course, at the beginnign of the analysis we didn't know which libraries were necessary, but we expanded this section as we made progress with the code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7068c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "\n",
    "import anvio.terminal as terminal\n",
    "import anvio.filesnpaths as filesnpaths\n",
    "\n",
    "from anvio.variabilityops import NucleotidesEngine\n",
    "from anvio.utils import store_dataframe_as_TAB_delimited_file\n",
    "\n",
    "run = terminal.Run(width=27)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c6766c",
   "metadata": {},
   "source": [
    "Here we define a Python function that takes a  set of anvi'o proifle-db and contigs-db files, and returns a comprehensive dictionary for the nucleotide variation per position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a14fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snvs(contigs_db_path, profile_db_path):\n",
    "    args = argparse.Namespace(contigs_db=contigs_db_path,\n",
    "                              profile_db=profile_db_path,\n",
    "                              gene_caller_ids='0',\n",
    "                              compute_gene_coverage_stats=True)\n",
    "\n",
    "    n = NucleotidesEngine(args, r=terminal.Run(verbose=False), p=terminal.Progress(verbose=False))\n",
    "    n.process()\n",
    "\n",
    "    return n.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2db626",
   "metadata": {},
   "source": [
    "Please note that this is done by passing a set of arguments to the `NucleotidesEngine` class that we imported from `anvio.variabilityops`. We learned what to import from ths library and how to format the `args` from the source code of `anvi-gen-variability-profile` program. Please also note the `gene_caller_ids=0` directive among the arguments passed to the class. The gene caller id `0` corresponds to the mobA gene in pBI143. Since our intention was to focus on mobA, here we limit all data we will acquire from the `NucleotidesEngine` class to that gene.\n",
    "\n",
    "The next function is a more complex one, but its sole purpose is to work with the sample names (which include information such as the unique family identifier, or whether a given sample belongs to the mother or an infant, etc) to summarize information about the mother-infant pairs remaining in our dataset, which is passed to the function as `udf`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f65690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mother_infant_pair_summary(udf, drop_incomplete_families=False):\n",
    "    # learn all the sample names that are present in the dataframe\n",
    "    sample_names = list(udf.sample_id.unique())\n",
    "\n",
    "    def get_countries(family_names):\n",
    "        # learn which countries are present in the datsaet by\n",
    "        # splitting that piece of information from sample names\n",
    "        country_names = [s.split('_')[0] for s in family_names]\n",
    "        return dict(zip(list(country_names), [country_names.count(i) for i in country_names]))\n",
    "\n",
    "    # we will create this intermediate dictionary to resolve sample names into\n",
    "    # some meaningful information about mother-infant pairs\n",
    "    mother_infant_pairs = {}\n",
    "    for sample_name in sample_names:\n",
    "        family_name = '_'.join(sample_name.split('_')[0:2])[:-1]\n",
    "        participant = sample_name.split('_')[1][-1]\n",
    "        day = sample_name.split('_')[2]\n",
    "\n",
    "        if family_name not in mother_infant_pairs:\n",
    "            mother_infant_pairs[family_name] = {'M': [], 'C': []}\n",
    "\n",
    "        mother_infant_pairs[family_name][participant].append(day)\n",
    "\n",
    "    # now we can learn about family names that include at least one mother\n",
    "    # and one infant:\n",
    "    family_names_with_both_M_and_C = [p for p in mother_infant_pairs if mother_infant_pairs[p]['M'] and mother_infant_pairs[p]['C']]\n",
    "\n",
    "    # now we subset the broader dictionary to have one that only includes\n",
    "    # complete families (this is largely for reporting purposes)\n",
    "    mother_infant_pairs_with_both_mother_and_infant = {}\n",
    "    for family_name in family_names_with_both_M_and_C:\n",
    "        mother_infant_pairs_with_both_mother_and_infant[family_name] = mother_infant_pairs[family_name]\n",
    "\n",
    "    # report some reports .. these will be printed to the user's screen\n",
    "    # when this function is called\n",
    "    run.info('Num entires', f\"{len(udf.index)}\")\n",
    "    run.info('Num samples', f\"{udf.sample_id.nunique()}\")\n",
    "    run.info('Num families', f\"{len(mother_infant_pairs)} / {get_countries(mother_infant_pairs.keys())}\")\n",
    "    run.info('   w/both members', f\"{len(mother_infant_pairs_with_both_mother_and_infant)} / {get_countries(mother_infant_pairs_with_both_mother_and_infant.keys())}\")\n",
    "\n",
    "    if drop_incomplete_families:\n",
    "        # reconstruct the original sample names for complete families:\n",
    "        sample_names_for_families_with_both_M_and_C = []\n",
    "        for family_name in mother_infant_pairs_with_both_mother_and_infant:\n",
    "            for day in mother_infant_pairs_with_both_mother_and_infant[family_name]['M']:\n",
    "                sample_names_for_families_with_both_M_and_C.append(f\"{family_name}M_{day}\")\n",
    "            for day in mother_infant_pairs_with_both_mother_and_infant[family_name]['C']:\n",
    "                sample_names_for_families_with_both_M_and_C.append(f\"{family_name}C_{day}\")\n",
    "\n",
    "        # return a new dataframe after dropping all sample names from incomplete families\n",
    "        # so we have a dataframe that is clean and reprsent only complete families (sad)\n",
    "        return udf[udf['sample_id'].isin(sample_names_for_families_with_both_M_and_C)]\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebe86e9",
   "metadata": {},
   "source": [
    "Now it is time to get single-nucleotide variant data for the mother-infant pairs from Finland, Sweden, USA, and Italy using the anvi'o project files we downloaded using the data pack before, using the fancy function `get_snvs` we defined above.\n",
    "\n",
    "It is important to note that the resulting data frames will contain information only for samples that include at least one SNV in the mobA gene of the plasmid. This means, samples that have no SNVs will not be reported in the following dataframes even though they were in the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f562c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin = get_snvs('fin/CONTIGS.db', 'fin/PROFILE.db')\n",
    "\n",
    "df_swe = get_snvs('swe/CONTIGS.db', 'swe/PROFILE.db')\n",
    "\n",
    "df_usa = get_snvs('usa/CONTIGS.db', 'usa/PROFILE.db')\n",
    "\n",
    "df_ita = get_snvs('ita/CONTIGS.db', 'ita/PROFILE.db')\n",
    "\n",
    "# combine all data frames\n",
    "df = pd.concat([df_fin, df_swe, df_usa, df_ita])\n",
    "\n",
    "# reset the `entry_id` column to make sure each entry has a\n",
    "# unique identifier:\n",
    "df['entry_id'] = range(0, len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60bb211",
   "metadata": {},
   "source": [
    "Now we take a quick look at the resulting dataframe that combines all data from all samples by simply sending this dataframe to the function `mother_infant_pair_summary` implemented above, so you can appreciate its true utility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3781c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mother_infant_pair_summary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7080b3e7",
   "metadata": {},
   "source": [
    "The dataframe `df` is quite a comprehensive one, as anvi'o generates an extremely rich output file to describe variants observed in metagenomes. We can take a very quick look, and go through the columns to have an idea (they scroll right):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f63d763",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d63fef",
   "metadata": {},
   "source": [
    "While this is our raw dataframe that contains all variants from all samples that had at least one variable nucleotide position in the mobA gene, it needs some cleaning.\n",
    "\n",
    "For instance, in some samples the mobA gene will have a pretty low coverage to perform a robus analysis of SNV patterns, and such samples should be removed first. Here are some of the samples that have the lowest coverage values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f1e5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df.gene_coverage.unique())[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dcad2a",
   "metadata": {},
   "source": [
    "For a very stringent analysis, here we can drop samples from our dataframe where the mobA gene has less than 50X coverage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22a745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = df.drop(df[df.gene_coverage < 50].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65378a03",
   "metadata": {},
   "source": [
    "The new dataframe `dfx` only contains samples that have enough reads to cover mobA at 50X or more. But as you can imagine, this removal step does not include any logic to 'maintain' families in the dataset. Following the removal of samples based on the coverage of mobA, now there will be some infants without mother samples, and some mother samples with no infants. Since the purpose of this analysis to investigate plasmid transfer through SNVs, we don't need those samples.\n",
    "\n",
    "And `mother_infant_pair_summary` comes to our rescue once again, as we request this function to further drop samples from `dfx` that belong to 'incomplete' families:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5aa0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = mother_infant_pair_summary(dfx, drop_incomplete_families=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f90136",
   "metadata": {},
   "source": [
    "In our final dataset, we have 49 families for which at least one mother metagenome and one infant metagenome was present.\n",
    "\n",
    "At this point we can report this final dataframe as a TAB-delmited file, an output that will be identical to an output `anvi-gen-variability-profile` would have generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c17d794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the file name in which we will store all the\n",
    "# final varaibility data:\n",
    "variability_profile_path = \"pBI143_SNVs.txt\"\n",
    "\n",
    "dfx.reset_index(drop=True, inplace=True)\n",
    "dfx[\"entry_id\"] = dfx.index\n",
    "\n",
    "# order by [corresponding_gene_call, codon_order_in_gene]\n",
    "dfx = dfx.sort_values(by = [\"corresponding_gene_call\", \"codon_order_in_gene\"])\n",
    "\n",
    "# ask anvi'o to store it:\n",
    "store_dataframe_as_TAB_delimited_file(dfx,\n",
    "                                      variability_profile_path,\n",
    "                                      columns=dfx.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fed9e7",
   "metadata": {},
   "source": [
    "If you wish, you can take a look at it in your terminal.\n",
    "\n",
    "The next step is to represent the information in this file as a network so we can visualize the relationships between all samples in the dataset with respect to their shared SNVs using Gephi. But first, we would like to generate a dictionary with sample information using sample names, so we can highlight samples that belong to the same family, etc.\n",
    "\n",
    "For this, we will parse the sample names, and create a dictionary, `sample_information_dict`, to pass to the `VariabiltyNetwork` class below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff71e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# an empty dictionary\n",
    "sample_information_dict = {}\n",
    "\n",
    "# get the final sample names from `dfx`\n",
    "sample_names = list(dfx.sample_id.unique())\n",
    "\n",
    "# go through each sample name, split it into pieces,\n",
    "# based on the `_` character, and fill in the\n",
    "# dictionary\n",
    "for sample_name in sample_names:\n",
    "    family_name = '_'.join(sample_name.split('_')[0:2])[:-1]\n",
    "    participant = sample_name.split('_')[1][-1]\n",
    "    day = sample_name.split('_')[2]\n",
    "    country = family_name.split('_')[0]\n",
    "    \n",
    "    sample_information_dict[sample_name] = {'family_name': family_name,\n",
    "                                            'participant': participant,\n",
    "                                            'country': country,\n",
    "                                            'sample_name': sample_name,\n",
    "                                            'coverage': dfx[dfx.sample_id == sample_name].gene_coverage.tolist()[0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aac71d5",
   "metadata": {},
   "source": [
    "The resulting is a very simple data structure that looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037da6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_information_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417455f1",
   "metadata": {},
   "source": [
    "Now it is time to ask anvi'o to convert all this into an XML file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e17e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anvio.variabilityops import VariabilityNetwork\n",
    "\n",
    "variability_network_path = \"pBI143_SNVs.gexf\"\n",
    "\n",
    "args = argparse.Namespace(input_file=variability_profile_path,\n",
    "                          include_competing_NTs='noise-robust',\n",
    "                          output_file=variability_network_path)\n",
    "\n",
    "variability_network = VariabilityNetwork(args, r=terminal.Run(verbose=False), p=terminal.Progress(verbose=False))\n",
    "variability_network.samples_information_dict = sample_information_dict\n",
    "variability_network.generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a01791a",
   "metadata": {},
   "source": [
    "You can now open the resulting XML file, [`pBI143_SNVs.gexf`](https://merenlab.org/data/pBI143/files/pBI143_SNVs.gexf), in [Gephi](https://gephi.org/) to visualize this network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
